# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eiqWwiE5SvXIgP9hCcIWyT4fvjwQbW7l
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load CSV
df = pd.read_csv('/content/spam.csv', encoding='latin-1')  # if encoding issue occurs
df = df[['Category', 'Message']]  # Keep only useful columns

# Rename for ease
df.columns = ['label', 'text']
df.dropna(inplace=True)

# Map labels
df['label'] = df['label'].map({'ham': 0, 'spam': 1})

print(df.head())
print(df['label'].value_counts())

def clean_text(text):
    text = text.lower()
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    return text

df['clean_text'] = df['text'].apply(clean_text)

def clean_text(text):
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", '', text, flags=re.MULTILINE)  # remove links
    text = re.sub(r'\@w+|\#','', text)  # remove mentions and hashtags
    text = re.sub(r'[^\w\s]', '', text)  # remove punctuation
    text = re.sub(r'\d+', '', text)  # remove numbers
    return text

df['clean_text'] = df['text'].apply(clean_text)
df[['text', 'clean_text']].head()

tfidf = TfidfVectorizer(stop_words='english', max_features=3000)
X_tfidf = tfidf.fit_transform(df['clean_text']).toarray()

# Already numeric labels
y = df['label'].values

# Standardizing TF-IDF data (not necessary for LR, but for SVM etc.)
scaler = StandardScaler(with_mean=False)
X_scaled = scaler.fit_transform(X_tfidf)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("âœ… Accuracy:", round(accuracy_score(y_test, y_pred) * 100, 2), "%")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear']
}

grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, verbose=1)
grid.fit(X_train, y_train)

best_model = grid.best_estimator_
print("ðŸ“Œ Best Params:", grid.best_params_)

def predict_message(msg):
    cleaned = clean_text(msg)
    tfidf_vec = tfidf.transform([cleaned])
    tfidf_vec_scaled = scaler.transform(tfidf_vec)
    prediction = best_model.predict(tfidf_vec_scaled)[0]
    return "Spam" if prediction == 1 else "Ham"

# Input Loop
while True:
    msg = input("ðŸ“© Enter message (type 'exit' to quit): ")
    if msg.lower() == 'exit':
        print("ðŸ‘‹ Exiting...")
        break
    print("ðŸ§  Prediction:", predict_message(msg))

